# ğŸ§  Teeow AI â€“ AI Assistant Service

A FastAPI-based microservice providing AI-powered chat functionality with conversation history and user management.

## ğŸš€ Features

- **FastAPI Backend**: High-performance API with async support
- **AI Integration**: Seamless integration with LLaMA models via Ollama
- **Database**: PostgreSQL for persistent storage of chat history and user data
- **RESTful API**: Well-documented endpoints with Swagger UI
- **Environment Configuration**: Easy setup with `.env` configuration
- **Containerized**: Ready for Docker deployment

## ğŸ—ï¸ Project Structure

```
teeow_ai/
â”œâ”€â”€ AI_assistant/             # Main application package
â”‚   â”œâ”€â”€ app/                  # Application code
â”‚   â”‚   â”œâ”€â”€ api/              # API routes
â”‚   â”‚   â”œâ”€â”€ core/             # Core functionality
â”‚   â”‚   â”œâ”€â”€ models/           # Database models
â”‚   â”‚   â”œâ”€â”€ schemas/          # Pydantic models
â”‚   â”‚   â””â”€â”€ main.py           # Application entry point
â”‚   â”œâ”€â”€ requirements.txt      # Python dependencies
â”‚   â””â”€â”€ .env.example         # Example environment variables
â”œâ”€â”€ .github/workflows/        # GitHub Actions workflows
â”œâ”€â”€ docker/                   # Docker configuration
â”œâ”€â”€ docs/                     # Documentation
â””â”€â”€ README.md                # This file
```

## ğŸ› ï¸ Prerequisites

- Python 3.8+
- PostgreSQL 12+
- Docker (optional, for containerized deployment)
- Ollama (for local model serving)

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/monaresh/teeow_ai.git
cd teeow_ai
```

### 2. Set Up Python Environment

```bash
# Create and activate virtual environment
python -m venv venv
.\venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r AI_assistant/requirements.txt
```

### 3. Database Setup

1. Create a new PostgreSQL database
2. Execute the SQL script to set up the schema:
   ```bash
   psql -U your_username -d your_database -f AI_assistant/schema.sql
   ```

### 4. Configuration

1. Copy the example environment file:
   ```bash
   cp AI_assistant/.env.example AI_assistant/.env
   ```
2. Update the `.env` file with your database credentials and other settings

### 5. Start Ollama with LLaMA Model

```bash
# Install Ollama (if not already installed)
# Download from https://ollama.ai/

# Pull and run the LLaMA model
ollama pull llama3.2
ollama run llama3.2
```

### 6. Run the Application

```bash
cd AI_assistant
uvicorn app.main:app --reload
```

The API will be available at `http://127.0.0.1:8000`

## ğŸ“š API Documentation

Once the application is running, access the interactive API documentation:
- Swagger UI: `http://127.0.0.1:8000/docs`
- ReDoc: `http://127.0.0.1:8000/redoc`

## ğŸ³ Docker Deployment

```bash
# Build the Docker image
docker build -t teeow-ai .

# Run the container
docker run -p 8000:8000 --env-file AI_assistant/.env teeow-ai
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘ Acknowledgments

- [FastAPI](https://fastapi.tiangolo.com/)
- [Ollama](https://ollama.ai/)
- [LLaMA](https://ai.meta.com/llama/)
- [PostgreSQL](https://www.postgresql.org/)

